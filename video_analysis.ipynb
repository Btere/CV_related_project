{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GbMEsogNQEwhNCG0zhvX2swoMnkHXiPf",
      "authorship_tag": "ABX9TyPont/RT6kNmNmMWYvfalgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Btere/CV_related_project/blob/main/video_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrD67phcp2bk"
      },
      "outputs": [],
      "source": [
        "#image analysis using opencv\n",
        "\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = Path(\"/content/drive/MyDrive/CV_Photo(n.).jpeg\")\n",
        "\n",
        "print(image_path)"
      ],
      "metadata": {
        "id": "xg1KhOrcp8gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(image_path)\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "RRn_9mrbp8kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show image\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "pQexmQyrp8mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# opencv uses a default colour for images-- BGR, so we need to transform it to RGB\n",
        "\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "dLXcpZ4lp8n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(gray)"
      ],
      "metadata": {
        "id": "TXPF_k2-p8qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#working with video\n",
        "\n",
        "video_path = Path(\"/content/drive/MyDrive/VID-20240804-WA0000.mp4\")\n"
      ],
      "metadata": {
        "id": "zBKTPqctp8sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture((video_path)) #capture the video"
      ],
      "metadata": {
        "id": "F5SdnJd7QunO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret, frame = cap.read() #grab a frame\n",
        "print(frame.shape)"
      ],
      "metadata": {
        "id": "2Cp8NK40QulP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print(f\"This is the number of frames/images in the video: {cap.get(cv2.CAP_PROP_FRAME_COUNT)}\")\n",
        "print(cap.get(cv2.CAP_PROP_FPS)) # time each frame per second plays."
      ],
      "metadata": {
        "id": "ZZcjdifOQudk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5687.0 / 29.99 #give me the length of the vide"
      ],
      "metadata": {
        "id": "qNKdslqvlJ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the image\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3RdHLEmJSRzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the total number of frame in the videos\n",
        "\n",
        "def show_frame():\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  # loop through each frame in the video\n",
        "  for frame_no in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "    ret, frame = cap.read()\n",
        "      # Show image\n",
        "    cv2.imshow('Video Player', gray)\n",
        "\n",
        "    # Breaking out of the loop\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Close down everything\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "a4C1mL_VSRxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "eZeSZ3mwSRe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Establish capture\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/VID-20240804-WA0000.mp4\")\n",
        "# Loop through each frame\n",
        "for frame_idx in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "\n",
        "    # Read frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Gray transform\n",
        "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Show image\n",
        "    #cv2.imshow('Video Player', gray)\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    # Breaking out of the loop\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Close down everything\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "IETKz3S0RUTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a pre-trained model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Load an image\n",
        "image_path = '/content/drive/MyDrive/CV_Photo(n.).jpeg'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Make predictions\n",
        "results = model(image)\n",
        "\n",
        "# Extract bounding boxes, labels, and confidence scores\n",
        "boxes = results.xyxy[0][:, :4].cpu().numpy()\n",
        "labels = results.xyxy[0][:, 5].cpu().numpy()\n",
        "scores = results.xyxy[0][:, 4].cpu().numpy()\n",
        "\n",
        "# Loop through each bounding box\n",
        "for i, box in enumerate(boxes):\n",
        "    x_min, y_min, x_max, y_max = map(int, box)\n",
        "    label = results.names[int(labels[i])]\n",
        "    score = scores[i]\n",
        "\n",
        "    # Draw the bounding box\n",
        "    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)  # Green box\n",
        "    cv2.putText(image, f'{label} {score:.2f}', (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrttPpMpRUMT",
        "outputId": "8e674034-8d20-4841-ff99-e7607547ee24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['gitpython>=3.1.30', 'pillow>=10.3.0'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pillow>=10.3.0\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.3/207.3 kB 7.7 MB/s eta 0:00:00\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 30.7 MB/s eta 0:00:00\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 172.8 MB/s eta 0:00:00\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, pillow, gitdb, gitpython\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pillow-10.4.0 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 6.1s, installed 2 packages: ['gitpython>=3.1.30', 'pillow>=10.3.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2024-8-15 Python-3.10.12 torch-2.3.1+cu121 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|██████████| 14.1M/14.1M [00:00<00:00, 29.2MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c694102c3314>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/CV_Photo(n.).jpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuG9JDVrRUHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMM74RegRUDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2gyG7uhRT_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrB1uZPhRT6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PMO4-GIRT25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}